{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T07:23:16.495697Z",
     "start_time": "2024-07-27T07:23:16.178889Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer\n",
    "qwen2_tokenizer = AutoTokenizer.from_pretrained(\"../model/Qwen2-7B\")\n",
    "llama3_tokenizer = AutoTokenizer.from_pretrained(\"../model/Meta-Llama-3.1-8B\")"
   ],
   "id": "919ae5842178201e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T07:23:17.986765Z",
     "start_time": "2024-07-27T07:23:17.981071Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "def tokenize(tokenizer):\n",
    "    domains = {}\n",
    "    content_length = {}\n",
    "    data_file_path = \"./data/part.jsonl\"\n",
    "    count = 0\n",
    "    with open(data_file_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            data = json.loads(line)\n",
    "            # print(data[\"content\"])\n",
    "            input_ids = tokenizer.encode(data[\"content\"])\n",
    "            if data[\"domain\"] in domains:\n",
    "                domains[data[\"domain\"]].append(len(input_ids))\n",
    "            else:\n",
    "                domains[data[\"domain\"]] = [len(input_ids)]\n",
    "            if data[\"domain\"] in content_length:\n",
    "                content_length[data[\"domain\"]].append(len(data[\"content\"]))\n",
    "            else:\n",
    "                content_length[data[\"domain\"]] = [len(data[\"content\"])]\n",
    "            count += 1\n",
    "    print(count)\n",
    "    for key, value in domains.items():\n",
    "        print(key, f\"数量{len(value)}\", f\"平均文本长度{np.mean(content_length[key])}\", f\"平均Token个数{np.mean(value)}\")\n",
    "    return domains, content_length"
   ],
   "id": "d86e8b31a9fe9a56",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T07:23:29.601745Z",
     "start_time": "2024-07-27T07:23:19.412122Z"
    }
   },
   "cell_type": "code",
   "source": [
    "domains, content_length = tokenize(qwen2_tokenizer)\n",
    "# 顺便统计 Qwen2 tokenizer 的压缩率\n",
    "total_length = sum(np.mean(values) for _, values in content_length.items())\n",
    "total_token_count = sum(np.mean(values) for _, values in domains.items())\n",
    "ratio = total_length / total_token_count\n",
    "print(f\"Qwen2 词表的平均压缩率为：{ratio}\")"
   ],
   "id": "653ace40c0e0b21d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (51621 > 32768). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1039\n",
      "paper 数量100 平均文本长度9050.51 平均Token个数2931.78\n",
      "book 数量91 平均文本长度141945.93406593407 平均Token个数54207.58241758242\n",
      "edu 数量99 平均文本长度477.7070707070707 平均Token个数317.4949494949495\n",
      "code 数量95 平均文本长度4423.831578947368 平均Token个数1123.6315789473683\n",
      "qa 数量80 平均文本长度1896.4 平均Token个数512.9375\n",
      "translation 数量100 平均文本长度153.35 平均Token个数48.03\n",
      "english 数量90 平均文本长度17162.3 平均Token个数3998.288888888889\n",
      "dialogue-tool 数量98 平均文本长度1561.4591836734694 平均Token个数482.6224489795918\n",
      "eu 数量100 平均文本长度8283.4 平均Token个数2481.0\n",
      "multi 数量86 平均文本长度21018.058139534885 平均Token个数7707.569767441861\n",
      "chinese 数量100 平均文本长度1470.0 平均Token个数964.42\n",
      "Qwen2 词表的平均压缩率为：2.7742154211216214\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T07:25:33.421325Z",
     "start_time": "2024-07-27T07:25:24.995689Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Llama3 技术报告中提高他们词表对于英文数据的压缩率是 3.94， 这里也统计一下\n",
    "domains, content_length = tokenize(llama3_tokenizer)\n",
    "total_length = sum(np.mean(values) for key, values in content_length.items() if key == \"english\")\n",
    "total_token_count = sum(np.mean(values) for key, values in domains.items() if key == \"english\")\n",
    "ratio = total_length / total_token_count\n",
    "print(f\"Llama3 词表对于英语数据的平均压缩率为：{ratio}\")"
   ],
   "id": "b87cd7c8b15cf0cf",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (204357 > 131072). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1039\n",
      "paper 数量100 平均文本长度9050.51 平均Token个数3059.96\n",
      "book 数量91 平均文本长度141945.93406593407 平均Token个数58310.142857142855\n",
      "edu 数量99 平均文本长度477.7070707070707 平均Token个数343.57575757575756\n",
      "code 数量95 平均文本长度4423.831578947368 平均Token个数1097.0736842105264\n",
      "qa 数量80 平均文本长度1896.4 平均Token个数512.95\n",
      "translation 数量100 平均文本长度153.35 平均Token个数53.02\n",
      "english 数量90 平均文本长度17162.3 平均Token个数3936.988888888889\n",
      "dialogue-tool 数量98 平均文本长度1561.4591836734694 平均Token个数490.4387755102041\n",
      "eu 数量100 平均文本长度8283.4 平均Token个数2432.99\n",
      "multi 数量86 平均文本长度21018.058139534885 平均Token个数7290.127906976744\n",
      "chinese 数量100 平均文本长度1470.0 平均Token个数1224.53\n",
      "Llama3 词表对于英语数据的平均压缩率为：4.359245221249178\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "bb986364a571a179"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
